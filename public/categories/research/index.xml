<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research | Kristian Brock</title>
    <link>https://www.kristianbrock.com/categories/research/</link>
      <atom:link href="https://www.kristianbrock.com/categories/research/index.xml" rel="self" type="application/rss+xml" />
    <description>Research</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 26 Feb 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.kristianbrock.com/img/icon-192.png</url>
      <title>Research</title>
      <link>https://www.kristianbrock.com/categories/research/</link>
    </image>
    
    <item>
      <title>Comparing dose-finding designs by simulation</title>
      <link>https://www.kristianbrock.com/post/comparing-dosefinding-simulations/</link>
      <pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://www.kristianbrock.com/post/comparing-dosefinding-simulations/</guid>
      <description>
&lt;script src=&#34;https://www.kristianbrock.com/post/comparing-dosefinding-simulations/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Mike Sweeting, Dan Slade, Dan Jackson and I (all of AstraZeneca) recently published a preprint &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-sweeting2023&#34;&gt;Sweeting et al. 2024&lt;/a&gt;)&lt;/span&gt; describing a simple method to improve efficiency when comparing dose-finding designs by simulation.
The preprint is available &lt;a href=&#34;https://arxiv.org/abs/2402.15460&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;in-a-nutshell&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;In a nutshell&lt;/h1&gt;
&lt;p&gt;Typically, when we investigate the performance of a dose-finding design, we run simulations.
If we are comparing several different designs (or variants of a design), we generally run simulations for each candidate design separately.
We tend to do this because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;this is how it is implemented in software;&lt;/li&gt;
&lt;li&gt;different designs are implemented in different packages;&lt;/li&gt;
&lt;li&gt;it might not strike us to do it differently.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, this is inefficient.
By running separate batches of simulations for different designs, we are effectively comparing different designs using different patients.
It would be much more efficient to use the same simulated patients on each candidate design.
Doing so would reduce the Monte Carlo (random) error inherent in using a finite number of iterations to estimate a limiting value.&lt;/p&gt;
&lt;p&gt;The trouble is, dose-finding designs are &lt;em&gt;adaptive&lt;/em&gt;, meaning some parameter of the trial (in this instance, the dose delivered and therefore the associated toxicity and efficacy probabilities) is dependent on the outcomes observed in other patients in the trial.
Our solution is to effectively simulate all possible binary toxicity (and efficacy) outcomes for a patient in advance by using latent uniform variables on &lt;span class=&#34;math inline&#34;&gt;\((0, 1)\)&lt;/span&gt;.
These can be interpreted as patient-level propensities.&lt;/p&gt;
&lt;p&gt;To illustrate, imagine a patient’s uniform toxicity propensity is sampled to be &lt;span class=&#34;math inline&#34;&gt;\(u_1 = 0.36\)&lt;/span&gt;.
This patient would be regarded as experiencing toxicity when treated at any dose with an associated toxicity probability exceeding 0.36.
This allows the same patient to behave consistently when having its dose selected by different designs in simulation.
The method works for toxicity-seeking designs like CRM, mTPI and BOIN; and also co-primary efficacy-toxicity designs like EffTox and BOIN12.
Full details are in the paper.&lt;/p&gt;
&lt;p&gt;The idea of using latent uniform variables to represent propensity to toxicity events has been proposed in different dose-finding contexts &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-o2002non&#34;&gt;O’Quigley, Paoletti, and Maccario 2002&lt;/a&gt;; &lt;a href=&#34;#ref-cheung2014simple&#34;&gt;Cheung 2014&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;code-implementation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Code implementation&lt;/h1&gt;
&lt;p&gt;Our proposal is implemented in v0.1.8 of the &lt;code&gt;escalation&lt;/code&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-escalation&#34;&gt;Brock, Slade, and Sweeting 2023&lt;/a&gt;)&lt;/span&gt;, now uploaded &lt;a href=&#34;https://cran.r-project.org/package=escalation&#34;&gt;to CRAN&lt;/a&gt;.
&lt;code&gt;escalation&lt;/code&gt; implements many different dose-finding designs with optional behaviour modifiers, making it perfect for comparing the performance of competing designs.&lt;/p&gt;
&lt;p&gt;To illustrate, let us reproduce an example from the package vignettes, comparing the behaviour of the perennial 3+3 design and two variants of the CRM in a five-dose scenario.
We start by defining the competing designs in a list with convenient names:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(escalation)

target &amp;lt;- 0.25
skeleton &amp;lt;- c(0.05, 0.1, 0.25, 0.4, 0.6)

designs &amp;lt;- 
  list(
    &amp;quot;3+3&amp;quot; = get_three_plus_three(num_doses = 5),
    &amp;quot;CRM&amp;quot; = get_dfcrm(skeleton = skeleton, target = target) %&amp;gt;%
      stop_at_n(n = 12),
    &amp;quot;Stopping CRM&amp;quot; = get_dfcrm(skeleton = skeleton, target = target) %&amp;gt;%
      stop_at_n(n = 12) %&amp;gt;%
      stop_when_too_toxic(dose = 1, tox_threshold = 0.35, confidence = 0.8)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we will compare three designs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3+3;&lt;/li&gt;
&lt;li&gt;CRM without a toxicity stopping rule;&lt;/li&gt;
&lt;li&gt;and an otherwise identical CRM design with a toxicity stopping rule.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The names we provide will be reused.&lt;/p&gt;
&lt;p&gt;For illustration we use only a modest number of replicates.
Feel free to investigate more replicates yourself.
We compare different designs using the &lt;code&gt;simulate_compare&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;num_sims &amp;lt;- 100
true_prob_tox &amp;lt;- c(0.12, 0.27, 0.44, 0.53, 0.57)

sims &amp;lt;- simulate_compare(
  designs, 
  num_sims = num_sims, 
  true_prob_tox = true_prob_tox
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Running 3+3 
## Running CRM 
## Running Stopping CRM&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We provide a convenient function to quickly visualise how the probability of selecting each dose in each design evolved as the simulations progressed.
The dose-levels are represented in the columns of this plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;convergence_plot(sims)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/comparing-dosefinding-simulations/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see immediately, for instance, that the designs generally agree that dose 2 is the best MTD candidate, and that the CRM designs are more likely to recommend doses 2, 3 and 4.
The differences between the two CRM variants are very small.
We can be more precise by formally contrasting the probability of selecting each dose for each pair of designs:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)

as_tibble(sims) %&amp;gt;% 
  filter(n %% 5 == 0) %&amp;gt;%
  ggplot(aes(x = n, y = delta)) +
  geom_point(size = 0.4) +
  geom_linerange(aes(ymin = delta_l, ymax = delta_u)) +
  geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;, col = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;iteration&amp;quot;) +
  facet_grid(comparison ~ dose,
             labeller = labeller(
               .rows = label_both,
               .cols = label_both)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/comparing-dosefinding-simulations/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All the work above is done by &lt;code&gt;as_tibble(sims)&lt;/code&gt;.
The rest of the code is just plotting.&lt;/p&gt;
&lt;p&gt;The error bars here reflect 95% symmetric asymptotic normal confidence intervals.
Change the &lt;code&gt;alpha = 0.05&lt;/code&gt; parameter when calling &lt;code&gt;as_tibble(sims)&lt;/code&gt; to get confident intervals for a different significance level.
Despite the small number of simulated iterates, we see that the two CRM variants are significantly more likely to recommend dose-level 2.&lt;/p&gt;
&lt;p&gt;We see that, even with the very small sample size of 50 simulated trials, the CRM designs are significantly more likely to recommend dose 3 than the 3+3 design.
In contrast, in this scenario there is very little difference at all between the two CRM variants.&lt;/p&gt;
&lt;p&gt;We also provide functions to get and set the patient-level propensities, allowing comparison and reproduction in other software packages.
Check out the “Comparing dose-escalation designs by simulation” vignette on the &lt;a href=&#34;https://cran.r-project.org/package=escalation&#34;&gt;CRAN package page&lt;/a&gt; and the &lt;a href=&#34;https://brockk.github.io/escalation/&#34;&gt;package documentation site&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-escalation&#34; class=&#34;csl-entry&#34;&gt;
Brock, Kristian, Daniel Slade, and Michael Sweeting. 2023. &lt;em&gt;Escalation: Modular Approach to Dose Finding Clinical Trials&lt;/em&gt;. &lt;a href=&#34;https://cran.r-project.org/package=escalation&#34;&gt;https://cran.r-project.org/package=escalation&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-cheung2014simple&#34; class=&#34;csl-entry&#34;&gt;
Cheung, Ying Kuen. 2014. &lt;span&gt;“Simple Benchmark for Complex Dose Finding Studies.”&lt;/span&gt; &lt;em&gt;Biometrics&lt;/em&gt; 70 (2): 389–97.
&lt;/div&gt;
&lt;div id=&#34;ref-o2002non&#34; class=&#34;csl-entry&#34;&gt;
O’Quigley, John, Xavier Paoletti, and Jean Maccario. 2002. &lt;span&gt;“Non-Parametric Optimal Design in Dose Finding Studies.”&lt;/span&gt; &lt;em&gt;Biostatistics&lt;/em&gt; 3 (1): 51–56.
&lt;/div&gt;
&lt;div id=&#34;ref-sweeting2023&#34; class=&#34;csl-entry&#34;&gt;
Sweeting, Michael, Daniel Slade, Daniel Jackson, and Kristian Brock. 2024. &lt;span&gt;“Potential Outcome Simulation for Efficient Head-to-Head Comparison of Adaptive Dose-Finding Designs.”&lt;/span&gt; &lt;em&gt;arXiv Preprint arXiv:2402.15460&lt;/em&gt;. &lt;a href=&#34;https://arxiv.org/abs/2402.15460&#34;&gt;https://arxiv.org/abs/2402.15460&lt;/a&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Sending me data in Excel</title>
      <link>https://www.kristianbrock.com/post/send-me-data/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://www.kristianbrock.com/post/send-me-data/</guid>
      <description>


&lt;div id=&#34;intro&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;I collaborate with lots of different researchers, helping them to analyse their data.
For simplicity, they almost always send me data in an Excel spreadsheet.
That is fine, but it is evidently not clear to most how to lay out the data to facilitate statistical analysis.&lt;/p&gt;
&lt;p&gt;Before I can analyse the data, I have to import it.
The way the data is saved really impacts how easy or hard it is to import.
There are some common mistakes that lots of researchers make.
The goal of this post is to describe how to lay out data in Excel so that it can be imported into R and analysed immediately.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rule-1---start-in-cell-a1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rule 1 - start in cell A1&lt;/h2&gt;
&lt;p&gt;When importing data from Excel, what the computer expects is a solid rectangle of data starting in cell A1.
Empty rows and columns may make the data more visually appealing to a human but they are guaranteed to confuse a computer.&lt;/p&gt;
&lt;p&gt;Put your first column header in cell A1, your second column header in B1, and so on.
Then put your data in the subsequent rows, using one row for each observation or subject.&lt;/p&gt;
&lt;p&gt;The computer will import values from cells as far out as the last non-empty column and as far down as the last non-empty row.
This means you cannot slap explanatory notes below your block of data because, to a computer, your note looks like malformed data.
If you want to provide notes, put them on a dedicated tab.&lt;/p&gt;
&lt;p&gt;How not to do it:
&lt;img src=&#34;Rule1.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rule-2---one-data-type-per-column&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rule 2 - One data-type per column&lt;/h2&gt;
&lt;p&gt;Broadly speaking, we work with numbers, text, and dates (which are in fact just a special type of number).&lt;/p&gt;
&lt;p&gt;When software imports data in columns, it works out the type of the column by inspecting the values in the individual cells.
If every value in a column is a number, then the column will be treated as numerical.
That is great because analysis (like calculating an average) can proceed with no fuss.&lt;/p&gt;
&lt;p&gt;However, all it takes is a single textual value in a column of otherwise numerical values for the entire column to be treated as text.
This is because the datatype chosen for a column has to be valid for every value in the column and text is the catch-all scenario.
If your column contains numbers, do not label missing values as “missing” or “not known” - just leave them blank.&lt;/p&gt;
&lt;p&gt;Equally, do not use inequalities like “&amp;lt; 0.5” because this too will be read as text and result in the entire column being treated as text.
The case with inequalities is tricky and could perhaps be handled gracefully using separate columns for the observed value and the lower and/or upper thresholds of precision, where applicable.&lt;/p&gt;
&lt;p&gt;How not to do it:
&lt;img src=&#34;Rule2.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rule-3---funky-column-names-are&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rule 3 - Funky column names are $?^£&lt;/h2&gt;
&lt;p&gt;Column names must be unique.
You cannot have two columns called “Data”, for instance.
Thus, meaningful column names with an appropriate level of detail are important.
However, column names should not be too complex.
This is because they will have to be typed out when the column is used in the analysis.
Each time a column name is typed, the chances of an error increase.&lt;/p&gt;
&lt;p&gt;Common examples of excessively complex column names are those that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;include units, like “Concentration (μmol/L)”&lt;/li&gt;
&lt;li&gt;enumerate the categorical levels, like “Sex (1=Female, 2=Male, 3=Non-binary, 4=Prefer not to say, 5=Missing)”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I advise that column names:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use letters and numbers (but do not start with a number)&lt;/li&gt;
&lt;li&gt;do not use spaces or symbols&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Capturing data from questionnaires can be tricky because there is a temptation to name the columns using the question text.
This will almost surely result in cumbersome column names.
In this situation, columns names “Q1”, “Q2”, etc are fine.
However, it would be advisable to also include a data-dictionary tab where the exact question text is listed against the question number.&lt;/p&gt;
&lt;p&gt;How not to do it:
&lt;img src=&#34;Rule3.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rule-4---be-consistent&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rule 4 - Be consistent&lt;/h2&gt;
&lt;p&gt;When entering column names and textual data values, be aware that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spelling matters: “Weather” is obviously different to “Whether”.&lt;/li&gt;
&lt;li&gt;Case matters: “Rainy” is different to “rainy”.&lt;/li&gt;
&lt;li&gt;Space matters: “Day of Week” is different to “DayofWeek”.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In Rule 3, I advocated not putting the levels of categorical variables in the column header because it is too prone to error.
It is absolutely fine to use descriptive textual labels like “Rainy” and “Sunny” rather than codified numerical values.
But when you choose your category values, stick with them.
Subtle ways in which categorical variables frequently differ are in capitalisation and use of space.&lt;/p&gt;
&lt;p&gt;If you want to codify categorical variables, that is fine but you it is advisable that you also include a data-dictionary tab where the codified values are listed against their textual values.&lt;/p&gt;
&lt;p&gt;How not to do it:
&lt;img src=&#34;Rule4.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rule-5---an-empty-cell-is-fine&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rule 5 - An empty cell is fine&lt;/h2&gt;
&lt;p&gt;In Rule 2, I told you not to label missing values.
An empty cell is absolutely fine.
If an particular piece of information is missing, just leave the cell empty.&lt;/p&gt;
&lt;p&gt;How not to do it:
&lt;img src=&#34;Rule5.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rule-6---stats-software-is-colourblind&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rule 6 - Stats software is colourblind&lt;/h2&gt;
&lt;p&gt;Researchers like to use cell shading to group related columns and make their data sheets easier to navigate.
That is absolutely fine…but do not expect stats software to detect your colouring, much less to understand what it means.&lt;/p&gt;
&lt;p&gt;In particular, do not convey important information in the formatting.
It will not work to use red shading or italics to convey approximate vs exact values, for instance.
All information should be conveyed in a dedicated column.
In this example, a column named MeasurementType taking values “Exact” and “Approximate” would be warranted.&lt;/p&gt;
&lt;p&gt;How not to do it:
&lt;img src=&#34;Rule6.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-ideal-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An ideal example&lt;/h2&gt;
&lt;p&gt;Obey all of those rules and you should come up with something that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Goal.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;An Excel sheet like this can be loaded into R and visualised or analysed immediately with no relabelling of columns, no re-casting of data-types, no data rejigging.
Make your data easier to analyse to get the analysis back quicker.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fitting the Emax Model in R</title>
      <link>https://www.kristianbrock.com/post/emax-intro/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      <guid>https://www.kristianbrock.com/post/emax-intro/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Let’s say we have some outcomes observed at different doses or exposures of some intervention.
Those data might look like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr)

df &amp;lt;- tibble(
  Exposure = c(10, 25, 50, 75, 100, 150, 300, 400),
  Response = c(0.03, 0.04, 0.15, 0.12, 0.25, 0.43, 0.54, 0.47)
)

df %&amp;gt;% 
  ggplot(aes(x = Exposure, y = Response)) + 
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/emax-intro/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Exposure-response relationships are incredibly common in medical research.
They do not just arise in phase I trials.&lt;/p&gt;
&lt;p&gt;The response variable could be interpreted as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the average level of target inhibition;&lt;/li&gt;
&lt;li&gt;the average concentration in serum;&lt;/li&gt;
&lt;li&gt;the percentage of subjects in a sample experiencing an event.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Likewise, the exposure variable could be interpreted as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the prevalence of some characteristic in a population;&lt;/li&gt;
&lt;li&gt;time spent in a certain state;&lt;/li&gt;
&lt;li&gt;the quantity of molecule popped into a patient’s mouth.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So how would we analyse data like this?
An ordinary linear model looks a bit of a stretch because the response variable appears to stop increasing at high exposures.
A generalised linear model (GLM) might be a fruitful approach.&lt;/p&gt;
&lt;p&gt;Here is a logit model fit to the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom)

df %&amp;gt;% 
  glm(data = ., formula = Response ~ Exposure, family = binomial(&amp;#39;logit&amp;#39;)) %&amp;gt;% 
  augment() %&amp;gt;% 
  mutate(Response = gtools::inv.logit(.fitted)) %&amp;gt;% 
  ggplot(aes(x = Exposure, y = Response)) + 
  geom_line() + 
  geom_point(data = df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/emax-intro/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;and here is a probit model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;% 
  glm(data = ., formula = Response ~ Exposure, family = binomial(&amp;#39;probit&amp;#39;)) %&amp;gt;% 
  augment() %&amp;gt;% 
  mutate(Response = gtools::inv.logit(.fitted)) %&amp;gt;% 
  ggplot(aes(x = Exposure, y = Response)) + 
  geom_line() + 
  geom_point(data = df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/emax-intro/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These fits are awful.
Both of these GLM approaches suffer from the same simple problem; they assume that the event probability tends to 1 as the linear predictor tends to infinity.
Put another way, there is no way for the response curve to asymptote to some value other than 1.0.
This bakes into the analysis that an event probability of 1.0 is not only possible, but guaranteed, given high enough exposure.
In many situations, this assumption is inappropriate.&lt;/p&gt;
&lt;p&gt;So what might we do instead?&lt;/p&gt;
&lt;div id=&#34;the-emax-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Emax Model&lt;/h2&gt;
&lt;p&gt;Emax is a non-linear model for estimating dose-response curves.&lt;/p&gt;
&lt;p&gt;The general model form is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R_i = E_o + \frac{D_i^N \times E_{max}}{D_i^N + {ED}_{50}^N}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(R_i\)&lt;/span&gt; is the response for experimental unit &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; is the exposure (or dose) of experimental unit &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(E_0\)&lt;/span&gt; is the expected response when exposure is zero, or the zero-dose effect, or the &lt;em&gt;basal effect&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(E_{max}\)&lt;/span&gt; is the maximum effect attributable to exposure;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(ED_{50}\)&lt;/span&gt; is the exposure that produces half of &lt;span class=&#34;math inline&#34;&gt;\(E_{max}\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(N &amp;gt; 0\)&lt;/span&gt; is the slope factor, determining the steepness of the dose-response curve.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Macdougall (2006)&lt;/span&gt; gives a fantastic introduction to the method, providing excellent interpretation of the parameters and summaries of the main model extensions.
We have borrowed here their notation and elementary explanation of model terms.&lt;/p&gt;
&lt;p&gt;The model variant above is called the &lt;em&gt;sigmoidal&lt;/em&gt; Emax model.
The variant with &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; fixed to take the value 1 is called the &lt;em&gt;hyperbolic&lt;/em&gt; model.&lt;/p&gt;
&lt;p&gt;Fitting this model to some data means estimating values for the free parameters, &lt;span class=&#34;math inline&#34;&gt;\(E_0, E_{max}, ED_{50}\)&lt;/span&gt;, and possibly &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, conditional on the observed &lt;span class=&#34;math inline&#34;&gt;\(R_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately, there are packages in R that will fit this model.
We introduce maximum likelihood and Bayesian approaches below.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;maximum-likelihood-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Maximum likelihood methods&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Bornkamp (2019)&lt;/span&gt; provides a function in the &lt;code&gt;DoseFinding&lt;/code&gt; package for fitting both the hyperbolic and sigmoidal model variants.&lt;/p&gt;
&lt;p&gt;We demonstrate first the hyperbolic approach, fitting it to our manufactured dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(DoseFinding)

emax0 &amp;lt;- fitMod(Exposure, Response, data = df,  model = &amp;quot;emax&amp;quot;)
plot(emax0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/emax-intro/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By default, the package uses &lt;code&gt;lattice&lt;/code&gt;-type graphics.
We see that the model fit is much better than the GLM approaches above.
To see the estimated parameters, we run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(emax0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Dose Response Model
## 
## Model: emax 
## Fit-type: normal 
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.08579 -0.03974  0.00223  0.02980  0.08854 
## 
## Coefficients with approx. stand. error:
##      Estimate Std. Error
## e0     -0.052      0.079
## eMax    0.827      0.172
## ed50  162.962    117.031
## 
## Residual standard error: 0.0698 
## Degrees of freedom: 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now fit the sigmoidal model.
This simply involves calling the same function with a different &lt;code&gt;model&lt;/code&gt; parameter:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emax1 &amp;lt;- fitMod(Exposure, Response, data = df,  model = &amp;quot;sigEmax&amp;quot;)
plot(emax1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/emax-intro/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is clear that the extra parameter dramatically improves the model fit.
Glimpsing the parameter values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(emax1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Dose Response Model
## 
## Model: sigEmax 
## Fit-type: normal 
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.0721 -0.0154  0.0120  0.0251  0.0389 
## 
## Coefficients with approx. stand. error:
##      Estimate Std. Error
## e0     0.0594     0.0324
## eMax   0.4515     0.0535
## ed50 107.0215    11.5670
## h      4.1370     1.6398
## 
## Residual standard error: 0.0497 
## Degrees of freedom: 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we learn that the &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; parameter (which they call &lt;code&gt;h&lt;/code&gt; to keep us on our toes) is not particularly consistent with the value 1.
The extra degree of freedom has roughly halved the estimated value of &lt;span class=&#34;math inline&#34;&gt;\(E_{max}\)&lt;/span&gt; and more than halved the associated standard error.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian methods&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;rstanemax&lt;/code&gt; package by &lt;span class=&#34;citation&#34;&gt;Yoshida (2019)&lt;/span&gt; implements a Bayesian version of Emax, offloading MCMC sampling to the miracle software Stan &lt;span class=&#34;citation&#34;&gt;(Carpenter et al. 2016)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Fitting the sigmoidal model is as simple as running code like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstanemax)

stan1 &amp;lt;- stan_emax(Response ~ Exposure, data = df, gamma.fix = NULL, 
                   seed = 12345, cores = 4, control = list(adapt_delta = 0.95))
stan1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: emax.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##         mean se_mean    sd  2.5%    25%    50%    75%  97.5% n_eff Rhat
## emax    0.51    0.00  0.12  0.35   0.44   0.48   0.55   0.86   681    1
## e0      0.04    0.00  0.04 -0.05   0.02   0.05   0.07   0.12  1409    1
## ec50  122.33    1.76 45.01 81.81 100.91 110.81 124.89 257.70   651    1
## gamma   3.66    0.06  2.03  0.96   2.18   3.32   4.74   8.67  1220    1
## sigma   0.07    0.00  0.03  0.03   0.05   0.06   0.08   0.14   923    1
## 
## Samples were drawn using NUTS(diag_e) at Wed May 13 19:15:55 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; parameter in this package is referred to as &lt;code&gt;gamma&lt;/code&gt; (still with me?) and the &lt;code&gt;gamma.fix = NULL&lt;/code&gt; argument causes the variable to be estimated from the data.
The argument name suggests you can provide your own fixed value - I have not investigated.
To fit the hyperbolic version, you just omit the &lt;code&gt;gamma.fix&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;We see that there is a little bit of difference in each of the estimated variables but nothing to get alarmed about.&lt;/p&gt;
&lt;p&gt;The package also provides a nice way of fetching predicted values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;samp &amp;lt;- rstanemax::posterior_predict(
  stan1, returnType = &amp;quot;tibble&amp;quot;, 
  newdata = tibble(exposure = seq(0, 400, length.out = 100)))

samp %&amp;gt;% head(10) %&amp;gt;% knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;mcmcid&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;exposure&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;emax&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;e0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ec50&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;gamma&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sigma&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;respHat&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;response&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07183650&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2860366&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.040404&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07187133&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3240279&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.080808&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07206919&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2041787&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.121212&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07254184&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0818142&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16.161616&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07338111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0172850&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20.202020&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07466294&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1978203&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.242424&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07644671&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2342920&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28.282828&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07877353&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0095302&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32.323232&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.08166463&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0747148&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36.363636&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1712489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0718365&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.70576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.741876&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1903292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.08512041&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0137214&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This facilitates my favourite method of visualising Bayesian model inferences: overplotting dots and lines.&lt;/p&gt;
&lt;p&gt;E.g. how does the expected curve look?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;samp %&amp;gt;% head(100 * 150) %&amp;gt;% 
  rename(Exposure = exposure, Response = respHat) %&amp;gt;% 
  ggplot(aes(x = Exposure, y = Response)) + 
  geom_point(data = df) +
  geom_line(aes(group = mcmcid), alpha = 0.1, col = &amp;#39;purple&amp;#39;) + 
  ylim(0, NA)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/emax-intro/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Each of the 150 purple lines above is a candidate for the mean exposure-response curve (or dose-response curve, if you prefer), hence the column name &lt;code&gt;respHat&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The subject-level predictions (i.e. the predictions with added noise) are also available in the &lt;code&gt;samp&lt;/code&gt; object via the &lt;code&gt;response&lt;/code&gt; column.
For instance, if you wanted to infer on the distribution of responses for a single unit (patient, dog, country, whatever) with given exposure, this is the distribution you would be using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;samp %&amp;gt;% head(100 * 100) %&amp;gt;% 
  rename(Exposure = exposure, Response = response) %&amp;gt;% 
  ggplot(aes(x = Exposure, y = Response)) + 
  geom_point(alpha = 0.1) +
  ylim(0, NA)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/emax-intro/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the plot above, responses are predicted at each of one hundred evenly-spaced exposures.
At each exposure, there are 100 points shown - i.e. each vertical tower contains exactly 100 points.
Thus, each dot represents a percentile.&lt;/p&gt;
&lt;p&gt;That is a bloody nice plot, isn’t it?
Time to sign off.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Next steps&lt;/h1&gt;
&lt;p&gt;In a forthcoming post I will fit the Emax model to outcomes in the dataset of phase I outcomes of &lt;span class=&#34;citation&#34;&gt;Brock et al. (2019)&lt;/span&gt; introduced in &lt;a href=&#34;post/dose-finding-data/&#34;&gt;this post&lt;/a&gt;.
Til then.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-DoseFinding&#34;&gt;
&lt;p&gt;Bornkamp, Bjoern. 2019. &lt;em&gt;DoseFinding: Planning and Analyzing Dose Finding Experiments&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=DoseFinding&#34;&gt;https://CRAN.R-project.org/package=DoseFinding&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-BrockDoseFindingData&#34;&gt;
&lt;p&gt;Brock, Kristian, Victoria Homer, Gurjinder Soul, Claire Potter, Cody Chiuzan, and Shing Lee. 2019. “Dose-Level Toxicity and Efficacy Outcomes from Dose-Finding Clinical Trials in Oncology.” &lt;a href=&#34;https://doi.org/10.25500/edata.bham.00000337&#34;&gt;https://doi.org/10.25500/edata.bham.00000337&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Carpenter2016&#34;&gt;
&lt;p&gt;Carpenter, Bob, Andrew Gelman, Matt Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus A. Brubaker, Peter Li, and Allen Riddell. 2016. “Stan: A Probabilistic Programming Language.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 76 (Ii): 1–32.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-macdougallAnalysisDoseResponse2006a&#34;&gt;
&lt;p&gt;Macdougall, James. 2006. “Analysis of Dose–Response Studies—Emax Model.” In &lt;em&gt;Dose Finding in Drug Development&lt;/em&gt;, edited by Naitee Ting, 127–45. New York, NY: Springer New York. &lt;a href=&#34;https://doi.org/10.1007/0-387-33706-7_9&#34;&gt;https://doi.org/10.1007/0-387-33706-7_9&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanemax&#34;&gt;
&lt;p&gt;Yoshida, Kenta. 2019. &lt;em&gt;Rstanemax: Emax Model Analysis with ’Stan’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=rstanemax&#34;&gt;https://CRAN.R-project.org/package=rstanemax&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Sample sizes in phase I</title>
      <link>https://www.kristianbrock.com/post/dose-finding-trial-sizes/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      <guid>https://www.kristianbrock.com/post/dose-finding-trial-sizes/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;I recently had reason to estimate the average size of a dose-escalation trial.
Based on my own experience, my immediate answer was “about 30 patients”.
However, using the data of &lt;span class=&#34;citation&#34;&gt;Brock et al. (2019)&lt;/span&gt; introduced in &lt;a href=&#34;post/dose-finding-data/&#34;&gt;this recent post&lt;/a&gt;, there is no reason to guess.
The dataset contains dose-level outcomes from 122 phase I clinical trial manuscripts reporting results of 139 dose-escalation experiments in cancer between 2008 and 2014.&lt;/p&gt;
&lt;p&gt;Perhaps surprisingly, we did not record the sample size of each trial.
The focus of the research was not phase I trials per se, but the outcomes seen at individual doses in phase I trials.
For that reason, we recorded the number of patients evaluable at each dose &lt;em&gt;for several outcomes&lt;/em&gt;, including toxicity and efficacy outcomes.
As &lt;a href=&#34;post/dose-finding-data/&#34;&gt;this post explains&lt;/a&gt;, the outcome most commonly reported was incidence of dose-limiting toxicity (DLT), with about 95% of studies reporting dose-level DLT data.
Thus, we can derive the number of patients in a dose-escalation study by summing the numbers of patients at each dose.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;empirical-sample-size-of-phase-i-trials&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Empirical sample size of phase I trials&lt;/h1&gt;
&lt;p&gt;With those caveats out the way, let’s load the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;https://raw.githubusercontent.com/brockk/dosefindingdata/master/Load.R&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and some required packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then calculate the number of patients in each study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable &amp;lt;- binary_events %&amp;gt;% 
  filter(OutcomeId == 1) %&amp;gt;% # This is DLT
  group_by(Study) %&amp;gt;% 
  summarise(NumPatients = sum(n), NumDoses = n()) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can simply visualise those summarised data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  ggplot(aes(x = NumPatients)) + 
  stat_count(aes(y = ..prop..), alpha = 0.5) + 
  geom_density(col = &amp;#39;blue&amp;#39;, size = 1.3) + 
  xlim(0, NA) + 
  labs(x = &amp;#39;Total sample size&amp;#39;, y = &amp;#39;Proportion&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/dose-finding-trial-sizes/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;to learn that the modal size is about &lt;span class=&#34;math inline&#34;&gt;\(n=20\)&lt;/span&gt;.
The distribution has a pronounced positive skew with a small number of relatively large sample sizes seen.&lt;/p&gt;
&lt;p&gt;Calculating summary statistics:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  pull(NumPatients) %&amp;gt;% 
  summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    6.00   18.00   23.00   27.38   33.00   93.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we see that the median size is 23 patients with an inter-quartile range of (18, 33).
My initial guess of about 30 was a bit toppy.&lt;/p&gt;
&lt;div id=&#34;by-drug-type&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;By drug type&lt;/h2&gt;
&lt;p&gt;The database also records various descriptive variables about the clinical scenarios.
We can, for example, investigate sample size by the type of drug that is having its dose varied.&lt;/p&gt;
&lt;p&gt;Let’s do that.
First, let us check which treatment types are contained:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  left_join(studies, by = &amp;#39;Study&amp;#39;) %&amp;gt;%
  count(DoseVaryingTreatmentType) %&amp;gt;% 
  arrange(-n) %&amp;gt;% 
  head(5) %&amp;gt;% knitr::kable(digits = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;DoseVaryingTreatmentType&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Chemotherapy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Inhibitor&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Monoclonal Antibody&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Chemotherapy + inhibitor&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Immunomodulatory drug&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We see that this period yielded trials mostly of chemotherapy and inhibitor drugs.
It really only makes sense to summarise sample sizes for those two categories:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  left_join(studies, by = &amp;#39;Study&amp;#39;) %&amp;gt;%
  filter(DoseVaryingTreatmentType %in% c(&amp;#39;Chemotherapy&amp;#39;, &amp;#39;Inhibitor&amp;#39;)) %&amp;gt;% 
  ggplot(aes(x = NumPatients)) + 
  stat_count(aes(y = ..prop..), alpha = 0.5) + 
  geom_density(col = &amp;#39;blue&amp;#39;, size = 1.3) + 
  xlim(0, NA) + 
  facet_wrap(~ DoseVaryingTreatmentType, ncol = 1) + 
  labs(x = &amp;#39;Total sample size&amp;#39;, y = &amp;#39;Proportion&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/dose-finding-trial-sizes/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The distributions look fairly exchangeable, suggesting that phase I trials of inhibitors have tended to use similar sizes to those of chemotherapies.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;haematological-vs-non-haematological&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Haematological vs non-haematological&lt;/h2&gt;
&lt;p&gt;We can instead contrast the sample sizes of trials in haematological and solid tumour (or non-haematological) diseases:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  left_join(studies, by = &amp;#39;Study&amp;#39;) %&amp;gt;%
  filter(HaemNonhaem %in% c(&amp;#39;Haematological&amp;#39;, &amp;#39;NonHaematological&amp;#39;)) %&amp;gt;% 
  ggplot(aes(x = NumPatients)) + 
  stat_count(aes(y = ..prop..), alpha = 0.5) + 
  geom_density(col = &amp;#39;blue&amp;#39;, size = 1.3) + 
  xlim(0, NA) + 
  facet_wrap(~ HaemNonhaem, ncol = 1) + 
  labs(x = &amp;#39;Total sample size&amp;#39;, y = &amp;#39;Proportion&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/dose-finding-trial-sizes/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, we see that the distributions are largely coincident.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sample-size-per-dose-investigated&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sample-size per dose investigated&lt;/h2&gt;
&lt;p&gt;We can plot sample size against the number of dose investigated to learn roughly how many patients are evaluated at each dose:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  ggplot(aes(x = NumDoses, y = NumPatients)) + 
  geom_point() + 
  geom_smooth(method = &amp;#39;loess&amp;#39;) + 
  xlim(0, NA)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/dose-finding-trial-sizes/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In one particular study, each patient received a different dose.
That is the outlier on the right of the plot above.
If we exclude that point, we get a better look at the relationship:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  filter(NumDoses &amp;lt; 20) %&amp;gt;% 
  ggplot(aes(x = NumDoses, y = NumPatients)) + 
  geom_point() + 
  geom_smooth(method = &amp;#39;loess&amp;#39;) + 
  xlim(0, NA)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/dose-finding-trial-sizes/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For numbers of doses less than about 10, the aggregate sample size is broadly linear in the number of doses.
How many patients per dose?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dlt_evaluable %&amp;gt;% 
  filter(NumDoses &amp;lt; 20) %&amp;gt;% 
  lm(NumPatients ~ NumDoses, data = .) %&amp;gt;% 
  broom::tidy() %&amp;gt;% knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.020828&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.6361675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.421948&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0008352&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;NumDoses&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.831117&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5030493&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.615787&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;About 4, with (3, 5) being a good working uncertainty interval.
That is not to say that phase I trials should be that size, of course!
Merely a reflection of what was done, on average, between 2008 and 2014.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-BrockDoseFindingData&#34;&gt;
&lt;p&gt;Brock, Kristian, Victoria Homer, Gurjinder Soul, Claire Potter, Cody Chiuzan, and Shing Lee. 2019. “Dose-Level Toxicity and Efficacy Outcomes from Dose-Finding Clinical Trials in Oncology.” &lt;a href=&#34;https://doi.org/10.25500/edata.bham.00000337&#34;&gt;https://doi.org/10.25500/edata.bham.00000337&lt;/a&gt;. &lt;a href=&#34;https://doi.org/10.25500/edata.bham.00000337&#34;&gt;https://doi.org/10.25500/edata.bham.00000337&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dataset containing outcomes from dose-finding trials in cancer</title>
      <link>https://www.kristianbrock.com/post/dose-finding-data/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      <guid>https://www.kristianbrock.com/post/dose-finding-data/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Do we expect the incidence of dose-limiting toxicity to increase as dose increases in dose-escalation clinical trials?
Categorically, yes.
The toxicologists’ epithet &lt;em&gt;sola dosis facit venenum&lt;/em&gt; or &lt;em&gt;the dose makes the poison&lt;/em&gt; says that any substance can be dangerous if administered in great enough quantities.&lt;/p&gt;
&lt;p&gt;What about efficacy?
Do we expect efficacy to be greater at higher doses?
Implicitly we must do whenever we use a method that seeks the &lt;em&gt;maximum tolerable dose&lt;/em&gt; (MTD).
The two adjectives in that phrase are fundamental to understanding the most common approach in dose-escalation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we seek the &lt;em&gt;maximum&lt;/em&gt; dose, i.e. we expressly favour higher doses;&lt;/li&gt;
&lt;li&gt;so long as the dose is &lt;em&gt;tolerable&lt;/em&gt;, i.e. it is associated with an acceptable toxicity probability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MTD-seeking methods are pervasive in the dose-finding literature.
Rule-based methods like the 3+3 seek the MTD.
&lt;span class=&#34;citation&#34;&gt;Rogatko et al. (2007)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Chiuzan et al. (2017)&lt;/span&gt; showed that the 3+3 method was predominant in dose-finding trials between 1991 and 2014.
Many model-based methods like the &lt;em&gt;continual reassessment method&lt;/em&gt; (CRM, &lt;span class=&#34;citation&#34;&gt;O’Quigley, Pepe, and Fisher (1990)&lt;/span&gt;) and &lt;em&gt;escalation with overdose control&lt;/em&gt; (EWOC, &lt;span class=&#34;citation&#34;&gt;Tighiouart and Rogatko (2010)&lt;/span&gt;) also seek the MTD.&lt;/p&gt;
&lt;p&gt;These methods decide dose by considering only toxicity outcomes.
The absence of efficacy from the decision reveals that there must be an assumption.
Specifically, MTD-seeking methods assume efficacy increases monotonically in dose.
Under this assuption, the MTD offers the best chance of efficacy for an acceptable risk of toxicity.&lt;/p&gt;
&lt;p&gt;But this is all just theory.
Science is a sceptical pursuit, and none are more sceptical than clinical trial statisticians.
The shift in cancer away from cytotoxic drugs (like chemotherapy) to cytostatic drugs (like targeted therapies) over the last two decades has provided more reason to be sceptical.&lt;/p&gt;
&lt;p&gt;So what evidence is there in recent clinical trials that the probability of toxicity increases in dose?
And more importantly, what evidence is there that the probability of efficacy increases in dose?&lt;/p&gt;
&lt;p&gt;Seeking to answer these questions motivated some researchers and I to gather data from many dose-finding clinical trials in cancer run between 2008 and 2014.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;methods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Methods&lt;/h1&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Chiuzan et al. (2017)&lt;/span&gt; conducted a systematic review of the methods used in cancer dose-finding trials.
Their findings mirrored those of &lt;span class=&#34;citation&#34;&gt;Rogatko et al. (2007)&lt;/span&gt; from the previous decade that the overwhelming majority of dose-finding trials (over 90%) use a rule-based design.
The assumption that efficacy increases in dose is evidently pervasive, irrespective the shift in research to targeted therapies.
I worked with Victoria Homer, Gurjinder Soul and Claire Potter of the University of Birmingham to extract dose-level outcomes from a large number of dose-finding trial publications to investigate the suitability of this assumption.&lt;/p&gt;
&lt;p&gt;In their review, Chiuzan &lt;em&gt;et al.&lt;/em&gt; found 1,712 manuscripts published between 2008 and 2014.
With the best will in the world, we would never be able to extract data from this many manuscripts.
Chiuzan &lt;em&gt;et al.&lt;/em&gt; published in their paper a large table summarising the trials that used model-based methods, like CRM or EWOC, of which there were 92 examples.
This number was feasible for data extraction.
However, the subset of trials that use model-based methods may not be representative of the entire sample.
With the cooperation of Shing Lee and Cody Chiuzan of Columbia University, we supplemented the list of 92 model-based papers with 30 randomly-selected manuscripts that used rule-based methods, to create a list of 122 manuscripts.&lt;/p&gt;
&lt;div id=&#34;data-items&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data items&lt;/h2&gt;
&lt;p&gt;Each of the 122 manuscripts presented the results of at least one dose-finding experiment in humans.
Some papers reported the results of more than one experiment.&lt;/p&gt;
&lt;p&gt;From each, we extracted:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;characteristic data, including:
&lt;ul&gt;
&lt;li&gt;type of cancer;&lt;/li&gt;
&lt;li&gt;name and type of experimental therapy;&lt;/li&gt;
&lt;li&gt;name and type of concommitant therapies;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;outcome data &lt;strong&gt;at each dose&lt;/strong&gt;, including:
&lt;ul&gt;
&lt;li&gt;dose level;&lt;/li&gt;
&lt;li&gt;number of patients evaluated;&lt;/li&gt;
&lt;li&gt;number of toxicity events recorded;&lt;/li&gt;
&lt;li&gt;number of efficacy events recorded.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;dose-level-outcomes-vs-pooled-outcomes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dose-level outcomes vs pooled outcomes&lt;/h3&gt;
&lt;p&gt;We expressly sought outcomes broken down by dose-level to investigate the suitability of the assumptions of monotonically increasing toxicity and efficacy.
We did not collect outcomes that were reported by pooling all dose-levels because this would not help answer our research questions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;toxicity-outcomes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Toxicity outcomes&lt;/h3&gt;
&lt;p&gt;Dose-limiting toxicity (DLT) is the de-facto standard safety outcome in dose-finding trials.
Manifestation of DLT involves the occurence of pre-specified adverse events (AEs) that are serious enough that they would motivate the clinician to not consider higher doses in the affected patient.
The precise definition of DLT varies from trial to trial but should always be detailed in the trial protocol.
The definition of DLT in a trial may reflect the clinical characteristics of the disease and the antipated adverse events from the entire treatment ensemble (i.e. arising from the experimental drug and concommitant drugs).
Data on DLT was sought in every manuscript.&lt;/p&gt;
&lt;p&gt;Where reported, we also collected other outcomes that reflected general drug safety, like &lt;em&gt;occurrence of grade 3-4 AE&lt;/em&gt; or &lt;em&gt;occurence of serious adverse event&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;efficacy-outcomes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Efficacy outcomes&lt;/h3&gt;
&lt;p&gt;The scientific question motivating this research concerns drug efficacy and how this changes as dose is increased.
&lt;em&gt;Efficacy&lt;/em&gt; is only loosely defined in cancer.
There is no single outcome that is unambiguously accepted as the variable best reflecting efficacy.&lt;/p&gt;
&lt;p&gt;Applications for drug licencing are generally supported by phase III trials that use survival-type outcomes like overall survival (OS) and progression-free survival (PFS).
In contrast, early phase trials, when they evaluate efficacy, tend to use surrogate outcomes that can be evaluated over the short-term like disease response.&lt;/p&gt;
&lt;p&gt;Assessing disease response generally involves comparing the extent of disease (e.g. tumour size or number of leukaemic cells) at baseline and after treatment administration to characterise the patient’s response to treatment using one of several categories.&lt;/p&gt;
&lt;p&gt;The most common response outcome categorisation used in cancer trials is RECIST response &lt;span class=&#34;citation&#34;&gt;(Eisenhauer et al. 2009)&lt;/span&gt;.
This scheme involves measuring the diameters of target solid tumour lesions and categorising the response as one of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;complete response (CR), when all target lesions disappear completely;&lt;/li&gt;
&lt;li&gt;partial response (PR), when lesions shrink in aggregate by a threshold amount, but remain measureable;&lt;/li&gt;
&lt;li&gt;progressive disease (PD), when lesions grow in aggregate by a threshold amount;&lt;/li&gt;
&lt;li&gt;stable disease (SD), when neither CR, PR nor PD occurs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are the RECIST criteria for assessing solid tumours.
Researchers have defined anlogues to these schemes in other cancers, including blood cancers where diseased cells reside in the blood rather than a discrete measurable tumour.
An example of this is the Cheson criteria in acute myeloid leukaemia (AML).&lt;/p&gt;
&lt;p&gt;Where reported, we recorded the incidence of these response categories by dose-level.&lt;/p&gt;
&lt;p&gt;Furthermore, researchers commonly derive additional outcomes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;objective response (OR), when CR or PR is observed;&lt;/li&gt;
&lt;li&gt;disease containment (DC), when CR, PR or SD occurs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We recorded these outcomes where reported, and imputed them where the components were available.
This involved adjustments to the definition of OR and DC to suit the response scheme.
For example, an objective response in AML included &lt;em&gt;complete response with incomplete marrow recovery&lt;/em&gt;, a response category signifiying relative treatment success that does not exist in RECIST.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;orderability-of-doses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Orderability of doses&lt;/h3&gt;
&lt;p&gt;Analysing how the probabilities of events change as dose increases requires that we are working with increasing doses.
The general 3+3, CRM and EWOC methods require that the doses under investigation are &lt;em&gt;fully orderable&lt;/em&gt;.
That is, we need to be able to unambiguously say that &lt;span class=&#34;math inline&#34;&gt;\(d_i &amp;lt; d_j\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(d_i &amp;gt; d_j\)&lt;/span&gt; for each &lt;span class=&#34;math inline&#34;&gt;\(d_i, d_j \in \mathcal{D} = \{ d_1, ..., d_n \}\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i \neq j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Despite this, we commonly encountered trials that used sets of doses that were not fully orderable.
When this happened, for the purposes of analysis, we broke the doses up to form fully orderable subsets that we called &lt;em&gt;analysis series&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There are many possible subsets of a set so the way we formed these series was unavoidably subjective.
We sought to maximise the size of the largest fully orderable series.
Furthermore, we avoided allocating a dose to several series unless repetition was the only way to avoid having an orphan dose (i.e. a series of size 1).&lt;/p&gt;
&lt;p&gt;In summary, the data have been recorded in a way amenable to answering the research questions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-extraction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data extraction&lt;/h2&gt;
&lt;p&gt;Data were extracted from papers and recorded on a prior-written standardised form, with one form for each manuscript.
The data were then recorded on sheets in an Excel file that was deposited in the University of Birmingham’s data repository.
Details on accessing the data are given below.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;div id=&#34;data-presence&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data presence&lt;/h2&gt;
&lt;p&gt;We can load the datasets by running:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;https://raw.githubusercontent.com/brockk/dosefindingdata/master/Load.R&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The script above hosted on GitHub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;loads the &lt;code&gt;readxl&lt;/code&gt;, &lt;code&gt;httr&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;, and &lt;code&gt;stringr&lt;/code&gt; packages;&lt;/li&gt;
&lt;li&gt;downloads the raw data file from the data repository;&lt;/li&gt;
&lt;li&gt;joins the raw datasets to create datasets useful for analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can check the number of manuscripts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

manuscripts %&amp;gt;% nrow&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 122&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the number of studies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;studies %&amp;gt;% nrow&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 139&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are more studies than manuscripts because some manuscripts report results from more than one dose-finding experiment.&lt;/p&gt;
&lt;p&gt;Characteristic data was available for every manuscript.
The clear majority of studies report toxicity outcomes by dose:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;studies %&amp;gt;% count(ToxByDose)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   ToxByDose     n
##   &amp;lt;lgl&amp;gt;     &amp;lt;int&amp;gt;
## 1 FALSE         6
## 2 TRUE        133&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Substantially fewer report efficacy outcomes by dose:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;studies %&amp;gt;% count(EffByDose)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   EffByDose     n
##   &amp;lt;lgl&amp;gt;     &amp;lt;int&amp;gt;
## 1 FALSE        54
## 2 TRUE         85&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The five outcomes reported most commonly are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;binary_events %&amp;gt;% 
  left_join(studies, by = &amp;#39;Study&amp;#39;) %&amp;gt;% 
  left_join(outcomes, by = &amp;#39;OutcomeId&amp;#39;) %&amp;gt;% 
  group_by(OutcomeClass, Outcome = OutcomeText) %&amp;gt;% 
  summarise(
    NumObs = n(), 
    NumStudies = length(unique(Study))
    ) %&amp;gt;% 
  mutate(ObsPerStudy = NumObs / NumStudies) %&amp;gt;% 
  arrange(-NumObs) %&amp;gt;% 
  head(5) %&amp;gt;% 
  knitr::kable(digits = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;OutcomeClass&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Outcome&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;NumObs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;NumStudies&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ObsPerStudy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Safety&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Patients with DLT&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;648&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;131&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Efficacy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Patients with Objective Response by RECIST&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;273&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Efficacy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Patients with Disease Control by RECIST&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;223&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;44&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Efficacy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Patients with Best response SD by RECIST&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;222&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;44&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Efficacy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Patients with Best response PD by RECIST&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;170&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We see that DLT is reported in the great majority of studies.
The most commonly-reported efficacy outcome is objective response by RECIST.
As described above, this outcome is only relevant in solid tumour settings.&lt;/p&gt;
&lt;p&gt;It was frustratingly common that toxicity would be reported by dose-level but efficacy would only be reported for all doses combined.
Naturally this impinges our ability to answer the research question.&lt;/p&gt;
&lt;p&gt;We found no papers reporting OS or PFS by dose-level.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;discussion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;This post introduced a substantial dataset on outcomes from dose-finding clinical trials.
It showed how to load the dataset and derive a few simple summary statistics on the number of studies and the frequency with which outcomes were reported.
Actually doing something useful with the data will be the subject of further posts.
For now, this post continues below with a full description of the data files.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;availability-of-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Availability of data&lt;/h1&gt;
&lt;p&gt;The datasets are available to download from &lt;a href=&#34;https://edata.bham.ac.uk/337/&#34; class=&#34;uri&#34;&gt;https://edata.bham.ac.uk/337/&lt;/a&gt;.
A full specification of the file format is give below.&lt;/p&gt;
&lt;p&gt;If you use the data, please cite:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Kristian Brock, Victoria Homer, Gurjinder Soul, Claire Potter, Cody Chiuzan and Shing Lee “Dose-level toxicity and efficacy outcomes from dose-finding clinical trials in oncology”. 2019. doi: 10.25500/edata.bham.00000337&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;or use the following BibTex entry:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{BrockDoseFindingData,
    author = {Kristian Brock and Victoria Homer and Gurjinder Soul and Claire Potter and Cody Chiuzan and Shing Lee},
    year = {2019},
    title = {Dose-level toxicity and efficacy outcomes from dose-finding clinical trials in oncology},
    doi = {10.25500/edata.bham.00000337},
    howpublished= {\url{https://doi.org/10.25500/edata.bham.00000337}},
    timestamp = {2019.05.05}
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;fast-loading-into-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fast loading into R&lt;/h2&gt;
&lt;p&gt;As demonstrated above, the fastest way to get the data loaded into R is to run the command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;https://raw.githubusercontent.com/brockk/dosefindingdata/master/Load.R&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, that runs code I have written on your machine so it requires that you trust me not to turn your computer into a bitcoin-mining drone in my distributed e-wealth empire.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;full-description-of-database-format&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Full description of database format&lt;/h1&gt;
&lt;p&gt;The file is called &lt;code&gt;database.xlsx&lt;/code&gt; and it contains many tabs.
The following sections describe in depth the format of the file.&lt;/p&gt;
&lt;div id=&#34;manuscripts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Manuscripts&lt;/h2&gt;
&lt;p&gt;This tab details the manuscripts studied in this research.&lt;/p&gt;
&lt;p&gt;Columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Manuscript&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Primary key for the manuscript in this project.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Year&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: Year manuscript was published.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DOI&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Manuscript DOI.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Source&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: How the manuscript came to be in the database. Options are:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ChiuzanModelBased&lt;/code&gt;, listed in &lt;span class=&#34;citation&#34;&gt;Chiuzan et al. (2017)&lt;/span&gt; as a trial using a model-based dose-finding design.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ChiuzanRuleBased1&lt;/code&gt;, randomly selected from the unpublished list of trials using rule-based dose-finding designs assembled by &lt;span class=&#34;citation&#34;&gt;Chiuzan et al. (2017)&lt;/span&gt; during their review.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SupplementAppendix&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if manuscript has a supplement or appendix.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DataExtraction1&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Person who extracted the data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DataExtraction2&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Person who extracted the data a second time or checked the first extraction.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AddToDB&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: TRUE if data has been added to the database.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Note&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Items noted during data extraction.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;studies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Studies&lt;/h2&gt;
&lt;p&gt;In this database, a &lt;code&gt;Study&lt;/code&gt; is an abstract concept encapsulating:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a set of doses of some treatment or combination of treatments;&lt;/li&gt;
&lt;li&gt;given to patients;&lt;/li&gt;
&lt;li&gt;yielding outcome data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In a simple scenario, one manuscript would contain one Study.
However, there can be multiple Studies in a manuscript.
For example, if more than treatment or treatment combination is the subject of dose investigation in a single manuscript, they are seperate studies.&lt;/p&gt;
&lt;p&gt;Columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Manuscript&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Foreign key to Manuscripts, reflecting the manuscript that reported the data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Study&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Primary key for the study in this project.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PatientGroup&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: brief description of the patient group.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PatientGroupDetailed&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: more detailed description of the patient group.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HaemNonhaem&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Options are:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Haematological&lt;/code&gt;, if the disease under study was haematological, like leukaemia or lymphoma.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NonHaematological&lt;/code&gt;, if the disease under study was solid tumour and therefore non-haematological, like lung cancer.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Mixed&lt;/code&gt;, if both disease types were studied.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unknown&lt;/code&gt;, where not specified.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Treatment&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: brief description of all treatments given, whether dose-varying or not.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ContainsChemo&lt;/code&gt;, &lt;code&gt;bit&lt;/code&gt;: &lt;code&gt;1&lt;/code&gt; if the treatment contains any chemotherapy element, fixed-dose or dose-varying. A full decomposition of treatment types is not provided here (e.g. there is no ContainsInhibitor field) but standardised types of the dose-varying treatment(s) are given in the column DoseVaryingTreatmentType.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FixedDoseChemo&lt;/code&gt;, &lt;code&gt;bit&lt;/code&gt;: &lt;code&gt;1&lt;/code&gt; if the treatment contains a fixed-dose chemotherapy component; &lt;code&gt;0&lt;/code&gt; if there is no fixed-dose chemo element. Note if chemotherapy is included only as part of the investigative treatment and thus has its dose varied, this field will be &lt;code&gt;0&lt;/code&gt;. This field is provided to address the reasonable expectation that the presence of a standard chemotherapy backbone increases the expectation of toxicity. A special case is made here for chemo to allow an analysis to reflect the reasonably-expected population-level effect that chemotherapy is associated with greater toxicity (and perhaps also response).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DoseVaryingTreatment&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: the treatment(s) that have their dose varied. In the case of many treatments, items are separated by the + symbol. Any treatment identified in Treatment but not in DoseVaryingTreatment can be assumed to be constant across the doses under investigation.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DoseVaryingTreatmentType&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: type of the treatment(s) undergoing dose variation. Options are:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Cell therapy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Chemoprevention&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Chemotherapy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cytokine&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GeneTherapy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Immunomodulatory drug&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Inhibitor&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Monoclonal Antibody&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Not disclosed&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Oncolytic virus&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Radiopharmaceutical&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Radiotherapy&lt;/code&gt;
or combinations thereof.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DoseVaryingTreatmentTypeDetail&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: more detailed and precise description of the type of dose-varying treatment, provided where available.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MultiVarying&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if the dose of several treatments was varied.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MonotonicDoses&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if the doses investigated are monotonically increasing.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DoseUnits&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: the units of the doses.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MTDorRP2D&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: the dose recommended as the MTD or RP2D.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ToxByDose&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if toxicity outcomes were reported by dose.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EffByDose&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if efficacy outcomes were reported by dose.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AdverseEventLevelCounts&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if adverse events were tabulated by dose for specific events (e.g. Anaemia) in contrast to the broad level (e.g. Grade 3/4 AE).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;outcomes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Outcomes&lt;/h2&gt;
&lt;p&gt;This tab details the outcome measures collected from the manuscripts.&lt;/p&gt;
&lt;p&gt;Columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;OutcomeId&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: Primary key for the outcome measure in this project.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OutcomeText&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Description of the outcome measure.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OutcomeClass&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Class of the outcome measure. Options are:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Safety&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Efficacy&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Include&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: This may be deprecated.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HighIsGood&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if a high value is a good thing for patients. FALSE otherwise. E.g. high response rate is good and low toxicity rate is good.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PerPatientOutcome&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if the outcome measure is binary at the patient level, e.g. “Any AE” is binary at the patient-level because a patient either experiences any AE (in which case it is &lt;code&gt;TRUE&lt;/code&gt;) or they do not (in which case it is &lt;code&gt;FALSE&lt;/code&gt;). In contrast, “Total AEs” is not binary because a patient may experience many AEs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Note&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Items noted during data extraction.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;binaryoutcomeevents&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;BinaryOutcomeEvents&lt;/h2&gt;
&lt;p&gt;This tab contains the data extracted from manuscripts on binary outcome measures.&lt;/p&gt;
&lt;p&gt;Columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Study&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Foreign key to Studies tab.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Dose&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Description of dose as reported. In the main, this is just a number, and simple to interpret. In more complicated scenarios, it could contain information reflecting: the frequency that treatments were given; several doses reported together like “10mg - 25mg” (an irritating practice - please do not do this); or doses for several treatments. The bewildering variety in this field is what encouraged us to think about &lt;em&gt;dose-levels&lt;/em&gt; (rather than actual doses) in monontonically increasing series.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OutcomeId&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: Foreign key to Outcomes tab.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: Number of patients. The denominator in a binary event rate.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Events&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: number of events.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Orphaned&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if the dose-level is orphaned and therefore has no unambiguous comparator.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;binaryoutcomeanalyisseries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;BinaryOutcomeAnalyisSeries&lt;/h2&gt;
&lt;p&gt;Doses investigated and reported in clinial trials are not always monotonically increasing, despite the fact that they should be under the most commonly-used experimental designs like 3+3 and CRM. Blithely analysing all of the doses as they are reported in publications would sometimes create scenarios where it is impossible to definitively say whether a dose is greater or less than some other (e.g. “5mg per day” vs “10mg every second day”; or “10mg of A + 5mg of B” vs “5mg of A + 10mg of B”).&lt;/p&gt;
&lt;p&gt;An analysis-series is a set of doses from a particular study that are strictly monotonically increasing, evaluated with respect to a particular outcome measure. There are many ways to create such subsets. The analysis series presented here are merely those preferred by the author. They favour series with as many doses as possible (whilst still retaining unambiguous monotonic order) and as little repetition as possible. A small amount of repetition has been tolerated where necessary to avoid an “orphaned” dose-level, i.e. a dose-level with no comparator.&lt;/p&gt;
&lt;p&gt;You are free to create our own analysis-series if you prefer.&lt;/p&gt;
&lt;p&gt;Columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NewSeries&lt;/code&gt;, &lt;code&gt;bit&lt;/code&gt;: This field exists to automate the generation of &lt;code&gt;AnalysisSeriesId&lt;/code&gt; and &lt;code&gt;Order&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AnalysisSeriesId&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: Primary key for the analysis series. Automatically generated by simple logic in Excel.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Order&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: The order of the dose in this analysis-series. Automatically generated by simple logic in Excel.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Study&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Foreign key to Studies tab.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Dose&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;: Description of dose as reported. In the main, this is just a number, and simple to interpret. In more complicated scenarios, it could contain information reflecting: the frequency that treatments were given; several doses reported together like “10mg - 25mg” (an irritating practice - please do not do this); or doses for several treatments. The bewildering variety in this field is what encouraged us to think about &lt;em&gt;dose-levels&lt;/em&gt; (rather than actual doses) in monontonically increasing series.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OutcomeId&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;: Foreign key to Outcomes tab.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Chiuzan2017&#34;&gt;
&lt;p&gt;Chiuzan, Cody, Jonathan Shtaynberger, Gulam A. Manji, Jimmy K. Duong, Gary K. Schwartz, Anastasia Ivanova, and Shing M. Lee. 2017. “Dose-Finding Designs for Trials of Molecularly Targeted Agents and Immunotherapies.” &lt;em&gt;Journal of Biopharmaceutical Statistics&lt;/em&gt; 27 (3): 477–94. &lt;a href=&#34;https://doi.org/10.1080/10543406.2017.1289952&#34;&gt;https://doi.org/10.1080/10543406.2017.1289952&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Eisenhauer2009&#34;&gt;
&lt;p&gt;Eisenhauer, E. A., P. Therasse, J. Bogaerts, L. H. Schwartz, D. Sargent, R. Ford, J. Dancey, et al. 2009. “New Response Evaluation Criteria in Solid Tumours: Revised RECIST Guideline (Version 1.1).” &lt;em&gt;European Journal of Cancer&lt;/em&gt; 45 (2): 228–47. &lt;a href=&#34;https://doi.org/10.1016/j.ejca.2008.10.026&#34;&gt;https://doi.org/10.1016/j.ejca.2008.10.026&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-OQuigley1990&#34;&gt;
&lt;p&gt;O’Quigley, J, M Pepe, and L Fisher. 1990. “Continual Reassessment Method: A Practical Design for Phase 1 Clinical Trials in Cancer.” &lt;em&gt;Biometrics&lt;/em&gt; 46 (1): 33–48. &lt;a href=&#34;https://doi.org/10.2307/2531628&#34;&gt;https://doi.org/10.2307/2531628&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Rogatko2007&#34;&gt;
&lt;p&gt;Rogatko, André, David Schoeneck, William Jonas, Mourad Tighiouart, Fadlo R. Khuri, and Alan Porter. 2007. “Translation of Innovative Designs into Phase I Trials.” &lt;em&gt;Journal of Clinical Oncology&lt;/em&gt; 25 (31): 4982–6. &lt;a href=&#34;https://doi.org/10.1200/JCO.2007.12.1012&#34;&gt;https://doi.org/10.1200/JCO.2007.12.1012&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Tighiouart2010&#34;&gt;
&lt;p&gt;Tighiouart, Mourad, and André Rogatko. 2010. “Dose Finding with Escalation with Overdose Control (EWOC) in Cancer Clinical Trials.” &lt;em&gt;Statistical Science&lt;/em&gt; 25 (2): 217–26. &lt;a href=&#34;https://doi.org/10.1214/10-STS333&#34;&gt;https://doi.org/10.1214/10-STS333&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulation or enumeration with dose-finding designs?</title>
      <link>https://www.kristianbrock.com/post/simulate-vs-enumerate-dose-finding/</link>
      <pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://www.kristianbrock.com/post/simulate-vs-enumerate-dose-finding/</guid>
      <description>
&lt;script src=&#34;https://www.kristianbrock.com/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.kristianbrock.com/rmarkdown-libs/viz/viz.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.kristianbrock.com/rmarkdown-libs/DiagrammeR-styles/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.kristianbrock.com/rmarkdown-libs/grViz-binding/grViz.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;If operating performance of a dose-finding clinical trial design is sought, it is practically guaranteed that this will be by computer simulation.
In a dose-finding simulation, a dose is initially selected and toxicity (and perhaps also efficacy) outcomes are sampled according to some assumed true event probabilities to generate data for some imaginary patients.
The model is fit to the data and the subsequent dose recommendation is given to the next group of imaginary patients.
This iterative and adaptive process continues to conduct a virtual trial.
In this manner, many virtual trials are run to inform the trialists of the operating performance of the design.&lt;/p&gt;
&lt;p&gt;However, simulating random virtual trials is not the only way to measure operating performance.
&lt;a href=&#34;https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/&#34;&gt;Richard McElreath said&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If there’s a random way to do something, there’s usually a less random way that is both better and requires more thought.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In dose-finding trials, a less random method is to calculate each trial path using brute force.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simple example&lt;/h2&gt;
&lt;p&gt;I demonstrated dose paths &lt;span class=&#34;citation&#34;&gt;(Yap et al. 2017; Brock et al. 2017)&lt;/span&gt; in a &lt;a href=&#34;https://www.kristianbrock.com/post/dose-paths/&#34;&gt;recent post&lt;/a&gt; using the &lt;code&gt;escalation&lt;/code&gt; package.
Let us walk through a simple example to see how dose-paths and simulation can be used to calculate operating characteristics for a dose-finding trial design.&lt;/p&gt;
&lt;p&gt;We load the escalation package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(escalation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: magrittr&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of illustration, let us use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a continual reassessment method (CRM) design&lt;/li&gt;
&lt;li&gt;in a three-dose setting&lt;/li&gt;
&lt;li&gt;to target a toxicity rate of 25%&lt;/li&gt;
&lt;li&gt;with a dose-toxicity skeleton that anticipates the middle dose is the sought dose:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;target &amp;lt;- 0.25
skeleton &amp;lt;- dfcrm::getprior(0.1, target = target, nu = 2, nlevel = 3)

model &amp;lt;- get_dfcrm(skeleton = skeleton, target = target) %&amp;gt;% 
        stop_at_n(n = 6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We told the model above to stop when the total sample size reached six patients.
Obviously, real trials would generally use larger sample sizes, but six patients will be enough for our illustrative example.&lt;/p&gt;
&lt;p&gt;Let us start the trial at the second dose and calculate all possible dose paths for two cohorts of three patients:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paths &amp;lt;- model %&amp;gt;% get_dose_paths(cohort_sizes = rep(3, 2), next_dose = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Viewing the paths makes clear that the decision space is finite and tractable to exact calculation of probabilities:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;graph_paths(paths)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:720px;height:720px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph {\n\ngraph [layout = \&#34;neato\&#34;,\n       outputorder = \&#34;edgesfirst\&#34;,\n       bgcolor = \&#34;white\&#34;]\n\nnode [fontname = \&#34;Helvetica\&#34;,\n      fontsize = \&#34;10\&#34;,\n      shape = \&#34;circle\&#34;,\n      fixedsize = \&#34;true\&#34;,\n      width = \&#34;0.5\&#34;,\n      style = \&#34;filled\&#34;,\n      fillcolor = \&#34;aliceblue\&#34;,\n      color = \&#34;gray70\&#34;,\n      fontcolor = \&#34;gray50\&#34;]\n\nedge [fontname = \&#34;Helvetica\&#34;,\n     fontsize = \&#34;8\&#34;,\n     len = \&#34;1.5\&#34;,\n     color = \&#34;gray80\&#34;,\n     arrowsize = \&#34;0.5\&#34;]\n\n  \&#34;1\&#34; [label = \&#34;2\&#34;, fontcolor = \&#34;#440154FF\&#34;, fillcolor = \&#34;#35B779FF\&#34;] \n  \&#34;2\&#34; [label = \&#34;3\&#34;, fontcolor = \&#34;#31688EFF\&#34;, fillcolor = \&#34;#FDE725FF\&#34;] \n  \&#34;3\&#34; [label = \&#34;3\&#34;, fontcolor = \&#34;#31688EFF\&#34;, fillcolor = \&#34;#FDE725FF\&#34;] \n  \&#34;4\&#34; [label = \&#34;2\&#34;, fontcolor = \&#34;#440154FF\&#34;, fillcolor = \&#34;#35B779FF\&#34;] \n  \&#34;5\&#34; [label = \&#34;2\&#34;, fontcolor = \&#34;#440154FF\&#34;, fillcolor = \&#34;#35B779FF\&#34;] \n  \&#34;6\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;7\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;8\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;9\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;10\&#34; [label = \&#34;3\&#34;, fontcolor = \&#34;#31688EFF\&#34;, fillcolor = \&#34;#FDE725FF\&#34;] \n  \&#34;11\&#34; [label = \&#34;2\&#34;, fontcolor = \&#34;#440154FF\&#34;, fillcolor = \&#34;#35B779FF\&#34;] \n  \&#34;12\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;13\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;14\&#34; [label = \&#34;2\&#34;, fontcolor = \&#34;#440154FF\&#34;, fillcolor = \&#34;#35B779FF\&#34;] \n  \&#34;15\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;16\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;17\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;18\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;19\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;20\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n  \&#34;21\&#34; [label = \&#34;1\&#34;, fontcolor = \&#34;#FDE725FF\&#34;, fillcolor = \&#34;#31688EFF\&#34;] \n\&#34;1\&#34;-&gt;\&#34;2\&#34; [label = \&#34;NNN\&#34;] \n\&#34;2\&#34;-&gt;\&#34;3\&#34; [label = \&#34;NNN\&#34;] \n\&#34;1\&#34;-&gt;\&#34;4\&#34; [label = \&#34;NNT\&#34;] \n\&#34;4\&#34;-&gt;\&#34;5\&#34; [label = \&#34;NNN\&#34;] \n\&#34;1\&#34;-&gt;\&#34;6\&#34; [label = \&#34;NTT\&#34;] \n\&#34;6\&#34;-&gt;\&#34;7\&#34; [label = \&#34;NNN\&#34;] \n\&#34;1\&#34;-&gt;\&#34;8\&#34; [label = \&#34;TTT\&#34;] \n\&#34;8\&#34;-&gt;\&#34;9\&#34; [label = \&#34;NNN\&#34;] \n\&#34;2\&#34;-&gt;\&#34;10\&#34; [label = \&#34;NNT\&#34;] \n\&#34;4\&#34;-&gt;\&#34;11\&#34; [label = \&#34;NNT\&#34;] \n\&#34;6\&#34;-&gt;\&#34;12\&#34; [label = \&#34;NNT\&#34;] \n\&#34;8\&#34;-&gt;\&#34;13\&#34; [label = \&#34;NNT\&#34;] \n\&#34;2\&#34;-&gt;\&#34;14\&#34; [label = \&#34;NTT\&#34;] \n\&#34;4\&#34;-&gt;\&#34;15\&#34; [label = \&#34;NTT\&#34;] \n\&#34;6\&#34;-&gt;\&#34;16\&#34; [label = \&#34;NTT\&#34;] \n\&#34;8\&#34;-&gt;\&#34;17\&#34; [label = \&#34;NTT\&#34;] \n\&#34;2\&#34;-&gt;\&#34;18\&#34; [label = \&#34;TTT\&#34;] \n\&#34;4\&#34;-&gt;\&#34;19\&#34; [label = \&#34;TTT\&#34;] \n\&#34;6\&#34;-&gt;\&#34;20\&#34; [label = \&#34;TTT\&#34;] \n\&#34;8\&#34;-&gt;\&#34;21\&#34; [label = \&#34;TTT\&#34;] \n}&#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Our first instinct might tell us that there are lots of terminal nodes that recommend dose 1 and relatively few that recommend dose 3.
We might then infer that selecting dose 1 is likely.
In fact, if the true toxicity probabilities at the three doses are (10%, 17%, 25%), we can calculate the exact operating performance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;probs &amp;lt;- c(0.10, 0.17, 0.25)
cdp &amp;lt;- paths %&amp;gt;% calculate_probabilities(true_prob_tox = probs)
prob_recommend(cdp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    NoDose         1         2         3 
## 0.0000000 0.1128170 0.4047377 0.4824453&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to learn that there is a 40.5% chance that the second dose will be recommended, and a 48.2% chance that the third dose will be recommended.&lt;/p&gt;
&lt;p&gt;The object name &lt;em&gt;cdp&lt;/em&gt; stands for &lt;em&gt;crystallised dose paths&lt;/em&gt;, my name for paths that have associated exact probabilities.
Simply printing the object to the console:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cdp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of nodes: 21 
## Number of terminal nodes: 16 
## 
## Number of doses: 3 
## 
## True probability of toxicity:
##    1    2    3 
## 0.10 0.17 0.25 
## 
## Probability of recommendation:
## NoDose      1      2      3 
##  0.000  0.113  0.405  0.482 
## 
## Probability of continuance:
## [1] 0
## 
## Probability of administration:
##      1      2      3 
## 0.0384 0.6757 0.2859 
## 
## Expected sample size:
## [1] 6
## 
## Expected total toxicities:
## [1] 1.141085&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;confirms the recommendation probabilities and many other statistics.&lt;/p&gt;
&lt;p&gt;The more common way to estimate dose-finding design performance is via simulation.
&lt;code&gt;escalation&lt;/code&gt; supports simulation too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sims100 &amp;lt;- model %&amp;gt;% 
  simulate_trials(num_sims = 100, true_prob_tox = probs, next_dose = 2)

sims1000 &amp;lt;- model %&amp;gt;% 
  simulate_trials(num_sims = 1000, true_prob_tox = probs, next_dose = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These, too, will estimate the probability that each dose will be recommended when the trial is done:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prob_recommend(sims100)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NoDose      1      2      3 
##   0.00   0.15   0.40   0.45&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prob_recommend(sims1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NoDose      1      2      3 
##  0.000  0.112  0.420  0.468&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the inferences from the simulations are subject to Monte Carlo error because we have used a finite number of samples to estimate an unknown probability.
If we collate the inferences from the dose-paths and simulations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tibble)
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trial_inference &amp;lt;- function(x, n) {
  dose_labs &amp;lt;- c(&amp;#39;NoDose&amp;#39;, dose_indices(x))
  tibble(Dose = dose_labs, ProbRecommend = prob_recommend(x), N = n) %&amp;gt;% 
    mutate(
      ProbRecommendSE = sqrt(ProbRecommend * (1 - ProbRecommend) / N),
      ProbRecommendL = ProbRecommend - 2 * ProbRecommendSE,
      ProbRecommendU = ProbRecommend + 2 * ProbRecommendSE
    )
}

inference &amp;lt;- bind_rows(
  trial_inference(cdp, n = Inf) %&amp;gt;% mutate(Method = &amp;#39;Exact&amp;#39;),
  trial_inference(sims100, n = 100) %&amp;gt;% mutate(Method = &amp;#39;Sims (N=100)&amp;#39;),
  trial_inference(sims1000, n = 1000) %&amp;gt;% mutate(Method = &amp;#39;Sims (N=1000)&amp;#39;),
) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we see the extent and effect of that estimation error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
inference %&amp;gt;% 
  ggplot(aes(x = Dose, y = ProbRecommend, col = Method)) + 
  geom_point(position = position_dodge(width = 0.3)) + 
  geom_errorbar(aes(ymin = ProbRecommendL, ymax = ProbRecommendU), 
                width = 0.1, position = position_dodge(width = 0.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/simulate-vs-enumerate-dose-finding/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we might anticipate, the simulation method is hopelessly imprecise with &lt;span class=&#34;math inline&#34;&gt;\(N=100\)&lt;/span&gt; iterations.
In contrast the simulations with &lt;span class=&#34;math inline&#34;&gt;\(N=1000\)&lt;/span&gt; iterations are fairly precise.&lt;/p&gt;
&lt;p&gt;Each simulated trial required that the dose selection model be fit twice, once at the end of each of the two cohorts.
A simulation study with 1000 iterations thus required 2000 model fits.
We might justifiably conclude that &lt;em&gt;fairly precise&lt;/em&gt; is a comparatively bad return on 2000 model invocations when the exact inferences from the dose paths required precisely 21 model fits, one for each of the nodes in the graph above.&lt;/p&gt;
&lt;p&gt;Dose paths are more precise than simulations because they are free from the Monte Carlo error that clouds inferences from simulations.
In this toy scenario, the paths method was also vastly more efficient, requiring only a small fraction of the model fits.&lt;/p&gt;
&lt;p&gt;However, this contrived example is unlikely to be representative of real trial scenarios, where we would expect much higher sample sizes.
This invites the question, how far can the dose paths method be taken?
When does it become more efficient to run simulations than attempting a brute force calculation?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-paths-at-scale&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculating paths at scale&lt;/h2&gt;
&lt;p&gt;Contrasting the computational efficiency of dose paths and simulations requires calculating the number of model invocations expected by each.&lt;/p&gt;
&lt;p&gt;For simulations, the arithmetic is simple.
Investigating a dose-finding trial of &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; cohorts in a single scenario using a simulation study with &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; replicates requires &lt;span class=&#34;math inline&#34;&gt;\(MN\)&lt;/span&gt; model invocations.
For example, a trial of &lt;span class=&#34;math inline&#34;&gt;\(n=30\)&lt;/span&gt; patients evaluated in 10 cohorts requires 10 model invocations, so 1000 simulated replicates requires &lt;span class=&#34;math inline&#34;&gt;\(10 \times 1000 = 10000\)&lt;/span&gt; model fits in total.&lt;/p&gt;
&lt;p&gt;In a dose paths analysis, the model must be fit once for each node in the graph.
The number of nodes in a dose paths analysis is slightly more complex to calculate (but only slightly).
Let &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; be the number of distinct outcomes a single patient may experience.
In a phase I trial using the CRM, each patient may experience toxicity (T) or no toxicity (N), so &lt;span class=&#34;math inline&#34;&gt;\(k= 2\)&lt;/span&gt;.
The number of outcome combinations in a cohort of &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; patients is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{(m + k - 1)!}{m! (k - 1)!} \]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For instance, a cohort of three patients has four possible outcomes: NNN, NNT, NTT, or TTT.
The formula above gives &lt;span class=&#34;math inline&#34;&gt;\((3 + 2 - 1)! / 3! (2 - 1)! = 4\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;That is the number of outcomes of a single cohort.
The number of nodes at depth &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in a graph of dose paths is equal to the number of nodes at depth &lt;span class=&#34;math inline&#34;&gt;\(i-1\)&lt;/span&gt; multiplied by the number of cohort outcomes at depth &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;.
There is always one node at depth 1 at the centre of the graph.
For a cohort of three in a CRM trial, we saw above that there are four possible outcomes.
Thus, at depth 2, there are 4 nodes and at depth 2 there are 16 nodes, etc.&lt;/p&gt;
&lt;p&gt;Naturally, the cohort sizes may be irregular.
In general, the number of nodes at depth &lt;span class=&#34;math inline&#34;&gt;\(I\)&lt;/span&gt; for cohort sizes &lt;span class=&#34;math inline&#34;&gt;\((m_1, ..., m_I)\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \prod_{i=1}^I \frac{(m_i + k - 1)!}{m_i! (k - 1)!} \]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately, there is a function in &lt;code&gt;escalation&lt;/code&gt; that calculates the number of nodes in a dose paths analysis.
Our simple example with &lt;span class=&#34;math inline&#34;&gt;\(n=6\)&lt;/span&gt; patients conducted in two cohorts of three has:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;num_dose_path_nodes(num_patient_outcomes = 2, cohort_sizes = c(3, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  1  4 16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;nodes at depths, 1, 2, and 3, respectively.
The total number of model invocations is the total number of nodes, which is 21, as required.&lt;/p&gt;
&lt;p&gt;We can use the function to calculate the number of nodes in an &lt;span class=&#34;math inline&#34;&gt;\(n=30\)&lt;/span&gt; trial with 10 cohorts of three patients:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- num_dose_path_nodes(num_patient_outcomes = 2, cohort_sizes = rep(3, 10))
n&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]       1       4      16      64     256    1024    4096   16384   65536
## [10]  262144 1048576&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The number of nodes increases exponentially in graph depth.
The total number of model fits is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1398101&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1.4m model fits is a substantial computational burden.&lt;/p&gt;
&lt;p&gt;Clearly dose number of nodes has increased dramatically as the number of cohorts has increased.
Let’s calculate the number of nodes contained in dose-paths of &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; cohorts of 3, for increasing values of M:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cohort_size &amp;lt;- 3
num_cohorts &amp;lt;- c(2, 3, 4, 5, 6, 7, 8, 9, 10) %&amp;gt;% as.integer()

library(purrr)
num_model_fits &amp;lt;- map_int(
  num_cohorts, 
  ~ num_dose_path_nodes(num_patient_outcomes = 2, 
                        cohort_sizes = rep(cohort_size, .x)) %&amp;gt;% sum()
)

num_model_fits&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]      21      85     341    1365    5461   21845   87381  349525 1398101&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;THese numbers are the total number of nodes.
The final value confirms that roughly 1.4m nodes feature in a graph of paths for eight cohorts of 3 patients.
Let’s view those numbers of model invocations alongside the equivalent for simulations with &lt;span class=&#34;math inline&#34;&gt;\(N=1000\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(10000\)&lt;/span&gt; replicates:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  tibble(NumCohorts = num_cohorts,
         NumModelFits = num_model_fits,
         Method = &amp;#39;Paths&amp;#39;),
  tibble(NumCohorts = num_cohorts,
         NumModelFits = 1000 * num_cohorts,
         Method = &amp;#39;Sims (N=1000)&amp;#39;),
  tibble(NumCohorts = num_cohorts,
         NumModelFits = 10000 * num_cohorts,
         Method = &amp;#39;Sims (N=10000)&amp;#39;),
) %&amp;gt;% 
  ggplot(aes(x = NumCohorts, y = NumModelFits, col = Method)) + 
  geom_point() + 
  geom_line() + 
  scale_y_log10() + 
  labs(y = &amp;#39;Number of model fits&amp;#39;, x = &amp;#39;Number of cohorts of 3 patients&amp;#39;,
       title = &amp;#39;Computational burden of dose paths and simulation&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/simulate-vs-enumerate-dose-finding/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis on the plot above is on the log-scale.
We see that the number of model fits in the dose paths analysis increases exponentially in the number of cohorts, as expected.
In contrast, the number of model fits required by simulations increases linearly in the number of cohorts, generally from a much higher base.
The result is that the paths analysis is more computationally efficient than simulations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;with &lt;span class=&#34;math inline&#34;&gt;\(N=1000\)&lt;/span&gt; iterations when there are fewer than 6 cohorts of 3;&lt;/li&gt;
&lt;li&gt;with &lt;span class=&#34;math inline&#34;&gt;\(N=10000\)&lt;/span&gt; iterations when there are fewer than 8 cohorts of 3.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perhaps we do not plan to use cohorts, intending instead to update the dose recommendation after each patient.
We can calculate the computational burdens in this situation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cohort_size &amp;lt;- 1
num_cohorts &amp;lt;- seq(from = 1, to = 30, by = 1)

num_model_fits &amp;lt;- map_int(
  num_cohorts, 
  ~ num_dose_path_nodes(num_patient_outcomes = 2, 
                        cohort_sizes = rep(cohort_size, .x)) %&amp;gt;% sum()
)

bind_rows(
  tibble(NumCohorts = num_cohorts,
         NumModelFits = num_model_fits,
         Method = &amp;#39;Paths&amp;#39;),
  tibble(NumCohorts = num_cohorts,
         NumModelFits = 1000 * num_cohorts,
         Method = &amp;#39;Sims (N=1000)&amp;#39;),
  tibble(NumCohorts = num_cohorts,
         NumModelFits = 10000 * num_cohorts,
         Method = &amp;#39;Sims (N=10000)&amp;#39;),
) %&amp;gt;% 
  ggplot(aes(x = NumCohorts, y = NumModelFits, col = Method)) + 
  geom_point() + 
  geom_line() + 
  scale_y_log10() + 
  labs(y = &amp;#39;Number of model fits&amp;#39;, x = &amp;#39;Number of patients&amp;#39;,
       title = &amp;#39;Computational burden of dose paths and simulation&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.kristianbrock.com/post/simulate-vs-enumerate-dose-finding/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, we see that paths are much more efficient for low sample sizes, but sample sizes in excess of 12 - 16 patients favour simulation.&lt;/p&gt;
&lt;p&gt;Assuming that dose-finding trials generally have sample sizes of 20-40 patients, that would seem to suggest that simulations clearly vanquish dose-paths for practical use.
However, there is one last major consideration to understand.&lt;/p&gt;
&lt;div id=&#34;dose-paths-can-be-recycled&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dose paths can be recycled&lt;/h3&gt;
&lt;p&gt;The computational burdens are calculated above for &lt;em&gt;a single batch of simulations&lt;/em&gt; corresponding to a &lt;em&gt;single set of assumed outcome probabilities&lt;/em&gt;.
Generally, simulation studies to justify dose-finding designs use many scenarios.
On the number of scenarios to investigate, &lt;span class=&#34;citation&#34;&gt;Wheeler et al. (2019)&lt;/span&gt; advocate that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the simulation study should include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scenarios where each dose is in fact the MTD;&lt;/li&gt;
&lt;li&gt;two extreme scenarios, in which the lowest dose is above the MTD and the highest dose is below the MTD;&lt;/li&gt;
&lt;li&gt;and any others that clinicians believe are plausible.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;where MTD means the &lt;em&gt;maximum tolerable dose&lt;/em&gt; or the notional target dose.
Thus, Wheeler &lt;em&gt;et al.&lt;/em&gt; advocate at least &lt;span class=&#34;math inline&#34;&gt;\(J + 2\)&lt;/span&gt; scenarios, where &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; is the number of doses under investigation.
The total computational burden for a simulation study of &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; scenarios is therefore bounded by &lt;span class=&#34;math inline&#34;&gt;\(NMS\)&lt;/span&gt;.
I say &lt;em&gt;bounded by&lt;/em&gt; rather than &lt;em&gt;equal to&lt;/em&gt; because some trials may stop early, depending on design.&lt;/p&gt;
&lt;p&gt;Simulations are arduous because in each scenario you start from scratch.
In stark contrast, dose-paths are reusable.
Calculating all dose paths is a relatively costly exercise.
But once they have been calculated, &lt;em&gt;crystallising&lt;/em&gt; the dose-paths with true outcome probabilities to calculate exact operating performance in a scenario is a relatively cheap computation.
The total computational burden under dose-paths will increase much slower than linearly in &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;.
Put another way, the time required to produce inference on one scenario is of the same order of magnitude as producing inference on many.
It pays to be thorough and with dose-paths, the incremental work to analyse an extra scenario is small.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The number of nodes in a graph of dose paths increases exponentially in the number of cohorts.
For 10 cohorts of three patients, approximately 10 times as many model fits are required in dose paths compared to simulations with &lt;span class=&#34;math inline&#34;&gt;\(N = 10000\)&lt;/span&gt; replicates (recall that the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axes above are logarithmic).
That is, we expect simulations to be computationally cheaper here if fewer than 10 scenarios are investigated.
When the models are evaluated after each patient, dose-paths using &lt;span class=&#34;math inline&#34;&gt;\(n=30\)&lt;/span&gt; patients require more than &lt;span class=&#34;math inline&#34;&gt;\(10^3 = 1000\)&lt;/span&gt; times the number of model fits.
Simulations are clearly preferable here.&lt;/p&gt;
&lt;p&gt;However, we know that dose-paths are more precise.
Unlike the simulation method, inferences from dose paths are exact because they are free from Monte Carlo error.&lt;/p&gt;
&lt;p&gt;When investigating the operating performance of a clinical trial design, researchers spend computer time to increase certainty.
When deciding whether to perform inference via dose paths or simulation, I propose there are three situations:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In trials with a small number of cohorts, dose-paths will be both faster and more precise and should naturally be the preferred method for inference.&lt;/li&gt;
&lt;li&gt;In trials with a modest number of cohorts and many scenarios to analyse, dose-paths will have a similar total computational burden to simulations.
In these situations, the extra precision of dose-paths will make them preferable.&lt;/li&gt;
&lt;li&gt;Finally there will be trials with a high number of cohorts where dose-paths are simply infeasible to calculate. Here, simulations will be preferred.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A way to investgate the value of the two methods in practice is, ironically, a simulation study.
This would require plausible assumptions on the number of model fits that should be expected in a trial and how many scenarios would be used to evaluate designs.
That feels like it needs a review of the literature but it will have to wait because today I am out of time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Brock2017a&#34;&gt;
&lt;p&gt;Brock, Kristian, Lucinda Billingham, Mhairi Copland, Shamyla Siddique, Mirjana Sirovica, and Christina Yap. 2017. “Implementing the EffTox Dose-Finding Design in the Matchpoint Trial.” &lt;em&gt;BMC Medical Research Methodology&lt;/em&gt; 17 (1): 112. &lt;a href=&#34;https://doi.org/10.1186/s12874-017-0381-x&#34;&gt;https://doi.org/10.1186/s12874-017-0381-x&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wheelerHowDesignDosefinding2019&#34;&gt;
&lt;p&gt;Wheeler, Graham M., Adrian P. Mander, Alun Bedding, Kristian Brock, Victoria Cornelius, Andrew P. Grieve, Thomas Jaki, et al. 2019. “How to Design a Dose-Finding Study Using the Continual Reassessment Method.” &lt;em&gt;BMC Medical Research Methodology&lt;/em&gt; 19 (1). &lt;a href=&#34;https://doi.org/10.1186/s12874-018-0638-z&#34;&gt;https://doi.org/10.1186/s12874-018-0638-z&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Yap2017&#34;&gt;
&lt;p&gt;Yap, Christina, Lucinda J. Billingham, Ying Kuen Cheung, Charlie Craddock, and John O’Quigley. 2017. “Dose Transition Pathways: The Missing Link Between Complex Dose-Finding Designs and Simple Decision-Making.” &lt;em&gt;Clinical Cancer Research&lt;/em&gt; 23 (24): 7440–7. &lt;a href=&#34;https://doi.org/10.1158/1078-0432.CCR-17-0582&#34;&gt;https://doi.org/10.1158/1078-0432.CCR-17-0582&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>CRM Simulation Checklist</title>
      <link>https://www.kristianbrock.com/post/crm-simulations-checklist/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://www.kristianbrock.com/post/crm-simulations-checklist/</guid>
      <description>&lt;p&gt;During 2019, I was working on simulations using CRM designs in several different trials.
I found I would frequently get the designs mixed up:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;We are targeting 20% toxicity in this trial, right? No, that was the other trial&amp;hellip;we are targeting 33% here&amp;hellip;&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Similarly, once or twice, I got to the stage where I wanted to run simulations only to discover we had not specified some important design aspect, like when the trial should stop.
To bring all the pertinent information to the fore, I wrote a checklist.
I would take the list and fill it out for each trial to ensure I had all the right information before I started simulating.&lt;/p&gt;
&lt;p&gt;Download the checklist as &lt;a href=&#34;https://www.kristianbrock.com/doc/CrmSimulationChecklist-1.0.pdf&#34;&gt;PDF&lt;/a&gt;, &lt;a href=&#34;https://www.kristianbrock.com/doc/CrmSimulationChecklist-1.0.docx&#34;&gt;editable Word version&lt;/a&gt;, or &lt;a href=&#34;https://www.kristianbrock.com/doc/CrmSimulationChecklist-Example-1.0.pdf&#34;&gt;completed example&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;checklist&#34;&gt;Checklist&lt;/h1&gt;
&lt;h3 id=&#34;1-doses-under-investigation&#34;&gt;1. Doses under investigation?&lt;/h3&gt;
&lt;p&gt;Put simply, which doses are you investigating?
And how many are there?
Let&amp;rsquo;s refer to the number of doses as $n$.
For the plain vanilla CRM, the doses should be fully orderable, meaning it should be possible to unambiguously state that $a &amp;gt; b$ or $a &amp;lt; b$ for each pair of doses $a, b$.
Incidentally, this is also true of the 3+3.
It is easy to inadvertently violate the &lt;em&gt;total orderability&lt;/em&gt; rule when you have combinations (e.g. is 10mg A + 10mb B a greater or lesser dose than 5mg A + 20mg B?) or when you are varying doses and frequencies (e.g. is 20mg of A each day a greater or lesser dose than 100mg of A once per week?).&lt;/p&gt;
&lt;h3 id=&#34;2-target-toxicity-level&#34;&gt;2. Target toxicity level?&lt;/h3&gt;
&lt;p&gt;What probability of dose-limiting toxicity are you targeting?
CRM and 3+3 are toxicity-chasing designs - they will escalate dose until toxicity is seen.
There must be a rationale for why escalation is anticipated to be beneficial to the patient.
So what probability of toxicity are you targeting?
If it is hard to specify an acceptable target, or the target is very low, that might be a sign that CRM and 3+3 are not suitable approaches.&lt;/p&gt;
&lt;h3 id=&#34;3-skeleton&#34;&gt;3. Skeleton?&lt;/h3&gt;
&lt;p&gt;What is your &lt;em&gt;a-priori&lt;/em&gt; expectation of the rate of toxicity at each dose?
This should be a monotonically-increasing vector of probabilities of length $n$.&lt;/p&gt;
&lt;h3 id=&#34;4-starting-dose&#34;&gt;4. Starting dose?&lt;/h3&gt;
&lt;p&gt;Which dose will you start at?
Having a dose or two to de-escalate to might be preferable in case your toxicity expectations are wrong.&lt;/p&gt;
&lt;h3 id=&#34;5-model-type&#34;&gt;5. Model type?&lt;/h3&gt;
&lt;p&gt;There have been various suggestions to model the dose-toxicity curve.
Will you use the empiric approach, or a one parameter logisitic approach, etc?&lt;/p&gt;
&lt;h3 id=&#34;6-model-parameters&#34;&gt;6. Model parameters?&lt;/h3&gt;
&lt;p&gt;Different model types require different parameters and hyperparameters.
E.g. the empiric model shifts the skeleton up and down as DLT outcomes are evaluated in patients, using a single parameter, often called $\beta$.
That parameter needs a prior distribution.
The default prior on $\beta$ in &lt;a href=&#34;https://cran.r-project.org/package=dfcrm&#34;&gt;dfcrm&lt;/a&gt; is $\beta \sim N(0, 1.34)$.
I will let you research why.&lt;/p&gt;
&lt;h3 id=&#34;7-how-to-select-dose&#34;&gt;7. How to select dose?&lt;/h3&gt;
&lt;p&gt;Will you select the dose with estimated DLT probability closest to the target?
Or closest to target without exceeding the target?
Will you permit skipping doses in escalation?
How about de-escalation?&lt;/p&gt;
&lt;h3 id=&#34;8-when-to-stop&#34;&gt;8. When to stop?&lt;/h3&gt;
&lt;p&gt;Trials end&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; - when will your trial end?
What is the maximum sample size?
Do you have a stopping rule for excess toxicity?
Do you want to evaluate a minimum number of patients at the candidate dose before you stop?
Also, check that these constraints do not contradict one another!&lt;/p&gt;
&lt;h3 id=&#34;9-length-of-dlt-assessment-window&#34;&gt;9. Length of DLT assessment window?&lt;/h3&gt;
&lt;p&gt;How long is the DLT assessment window?&lt;/p&gt;
&lt;h2 id=&#34;if-using-non-time-to-event-method&#34;&gt;If using non-time-to-event method:&lt;/h2&gt;
&lt;h3 id=&#34;10-how-to-select-cohort-size&#34;&gt;10. How to select cohort size?&lt;/h3&gt;
&lt;p&gt;Commonly, designs have used fixed cohort sizes of three.
But perhaps you want to use flexible cohort sizes of 2-5 patients, depending on the times at which the patients arrive?
How will you simulate this?&lt;/p&gt;
&lt;h2 id=&#34;if-using-time-to-event-method&#34;&gt;If using time-to-event method:&lt;/h2&gt;
&lt;h3 id=&#34;11-how-to-calculate-weight-of-observation&#34;&gt;11. How to calculate weight of observation?&lt;/h3&gt;
&lt;p&gt;Under the Time-to-Event CRM (TITE-CRM), censored observations of non-DLT are weighted somewhere between 0 and 1.
Logically, the weight should be a non-decreasing function of the length of follow-up.
If DLT is experienced, the weight should be 1.
Several weight functions have been proposed.
A simple option is linear, i.e. 50% of the evaluation period without DLT is considered to be 0.5 non-DLT events.&lt;/p&gt;
&lt;h2 id=&#34;for-simulation&#34;&gt;For simulation:&lt;/h2&gt;
&lt;h3 id=&#34;12-what-is-assumed-true-probdlt&#34;&gt;12. What is assumed true Prob(DLT)?&lt;/h3&gt;
&lt;p&gt;The key simulation parameter, what is the true probability of DLT at each dose?
It will be tempting to choose a true dose-DLT curve that looks similar to your skeleton but do not stop there.
Naturally, a thorough simulation study will look at many true dose-DLT curves, with the sought dose appearing at different positions.
If you have a rule for early stopping, you might want to consider a scenario where the true DLT probabilities are all too high.&lt;/p&gt;
&lt;h2 id=&#34;for-simulation-using-time-to-event-method&#34;&gt;For simulation using time-to-event method:&lt;/h2&gt;
&lt;h3 id=&#34;13-what-is-time-between-patient-arrivals&#34;&gt;13. What is time between patient arrivals?&lt;/h3&gt;
&lt;p&gt;When simulating using the TITE-CRM method, you will need to randomly sample patient arrival times.
For memoryless waiting times, the exponential distribution would do the job.&lt;/p&gt;
&lt;h3 id=&#34;14-what-is-time-between-patient-arrivals&#34;&gt;14. What is time between patient arrivals?&lt;/h3&gt;
&lt;p&gt;Generally in simulation, you sample whether toxicity will happen in a patient given their assigned dose and the associated probability of DLT using a random draw from a Bernoulli distribution.
Once you have established that toxicity occurs in a given patient, you will need to sample the time of the DLT.
How will you do that?
You might assume a constant hazard, for example, and thus use an exponential distribution.
Obviously, if a patient does not experience DLT then their DLT time is infinite.&lt;/p&gt;
&lt;h1 id=&#34;availability-of-software&#34;&gt;Availability of software&lt;/h1&gt;
&lt;p&gt;Having made all these choices (and it is exhausting to even think of all these things), you then have to find or write code to make it happen.
You may find you do not have the time or programming skill to write exactly what you want and opt for an off-the-shelf solution.
Each of &lt;a href=&#34;https://cran.r-project.org/package=dfcrm&#34;&gt;dfcrm&lt;/a&gt;, &lt;a href=&#34;https://cran.r-project.org/package=bcrm&#34;&gt;bcrm&lt;/a&gt;, and &lt;a href=&#34;https://cran.r-project.org/package=crmPack&#34;&gt;crmPack&lt;/a&gt; offer methods for simulating CRM trials, and my very own &lt;a href=&#34;https://www.kristianbrock.com/project/trialr/&#34;&gt;trialr&lt;/a&gt; will have CRM simulation methods soon.
However, each differs in what they offer (that feels like a blog post for another day).
You may discover that no off-the-shelf package does exactly what you want and find yourself tweaking your choices above in light of what is feasible.
It is an iterative process.&lt;/p&gt;
&lt;h3 id=&#34;read-more&#34;&gt;Read more&lt;/h3&gt;
&lt;p&gt;Graham Wheeler and co-authors &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; wrote a tutorial for designing dose-finding trials using the CRM.
You can read more about that article &lt;a href=&#34;https://www.kristianbrock.com/publication/crm-tutorial/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h3&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;even &lt;a href=&#34;http://www.stampedetrial.org/&#34;&gt;STAMPEDE&lt;/a&gt;, one imagines. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Wheeler, G.M., Mander, A.P., Bedding, A., Brock, K., Cornelius, V., Grieve, A.P., Jaki, T., Love, S.B., Odondi, L., Weir, C.J., Yap, C., Bond, S.J., 2019. How to design a dose-finding study using the continual reassessment method. BMC Medical Research Methodology 19. &lt;a href=&#34;https://doi.org/10.1186/s12874-018-0638-z&#34;&gt;https://doi.org/10.1186/s12874-018-0638-z&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>
